"""
Script para treinar e avaliar modelo R-GCN nos grafos de conhecimento constru√≠dos 
com a metodologia MultiStatGraph Framework para detec√ß√£o de fraude financeira.

METODOLOGIA KNOWLEDGE GRAPH HETEROG√äNEO:
- Grafo heterog√™neo multi-relacional com 6 tipos de n√≥s e 7 tipos de arestas
- Grafos pr√©-normalizados: features enriquecidas com conhecimento contextual
- Estrutura multi-relacional: 6 camadas de conectividade especializada
- Modelo: R-GCN (Relational Graph Convolutional Network)

TIPOS DE N√ìS SUPORTADOS:
- TRANSACTION: 85,200 n√≥s com 110 features enriquecidas (features originais + contextuais)
- CARD: 6,917 entidades de cart√£o com features de risco
- ADDRESS: 132 entidades de endere√ßo com agrega√ß√µes temporais  
- EMAIL: 106 dom√≠nios de email com scores de reputa√ß√£o
- PRODUCT: 5 categorias de produto com estat√≠sticas
- TEMPORAL: 104 janelas temporais para contexto

TIPOS DE ARESTAS SUPORTADOS:
- transaction -> transaction: relates_to (identidade + similaridade + anomalia + temporal)
- transaction -> card: uses_card (relacionamentos de uso)
- transaction -> address: at_address (localiza√ß√£o)
- transaction -> email: uses_email (comunica√ß√£o)
- transaction -> product: buys_product (categoria)
- transaction -> temporal: in_timewindow (contexto temporal)
- temporal -> temporal: sequential (sequ√™ncia temporal)

Este script implementa um pipeline completo de treinamento incluindo:
- Carregamento de grafos heterog√™neos (HeteroData)
- Defini√ß√£o de arquitetura R-GCN especializada
- Treinamento com early stopping e mixed precision
- Avalia√ß√£o com m√©tricas cient√≠ficas padr√£o focadas em n√≥s de transa√ß√£o

Autor: Sistema MultiStatGraph Knowledge Framework
Data: 2025-06-29 (Adaptado para R-GCN espec√≠fico)
Projeto: GraphSentinel 2.0 - Detec√ß√£o de Fraude com R-GCN
Vers√£o: 6.0 (R-GCN Framework - IEEE-CIS Dataset Heterog√™neo)
"""

from typing import Dict, Any, Tuple
import warnings
import os
import logging
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import random
import argparse
import json
import time
from datetime import datetime

# Filtrar avisos espec√≠ficos do torch-scatter
warnings.filterwarnings("ignore", message="The usage of `scatter\\(reduce='max'\\)` can be accelerated")
warnings.filterwarnings("ignore", message="The usage of `scatter\\(reduce='mean'\\)` can be accelerated")

from torch_geometric.data import HeteroData
from torch_geometric.nn import RGCNConv

from sklearn.metrics import (
    roc_auc_score, 
    recall_score, 
    fbeta_score, 
    average_precision_score,
    precision_score,
    precision_recall_curve
)

# üî¨ SEED CIENT√çFICO FIXO PARA REPRODUTIBILIDADE
# Garantindo avalia√ß√£o cient√≠fica rigorosa de diferentes tipos de grafo
SCIENTIFIC_SEED = 42  # Seed global usado em todos os modelos para compara√ß√£o justa


def load_hetero_graph(file_path: str, device: torch.device, graph_type: str = 'knowledge') -> HeteroData:
    """
    Carrega grafo de conhecimento heterog√™neo PyTorch j√° processado com m√°scaras de divis√£o.
    
    METODOLOGIA KNOWLEDGE GRAPH HETEROG√äNEO:
    - Grafo heterog√™neo com 6 tipos de n√≥s e 7 tipos de arestas
    - Features PR√â-NORMALIZADAS e enriquecidas do dataset IEEE-CIS
    - M√°scaras de divis√£o: train_mask, val_mask, test_mask nos n√≥s de transa√ß√£o
    - isFraud APENAS como target (y), N√ÉO como feature de entrada (X)
    
    Args:
        file_path (str): Caminho para o arquivo PyTorch (.pt) do grafo heterog√™neo
        device (torch.device): Dispositivo para carregar os dados (CPU/GPU)
        graph_type (str): Tipo de grafo ('knowledge' - grafo heterog√™neo)
    
    Returns:
        HeteroData: Objeto PyTorch Geometric HeteroData com m√°scaras e conectividade heterog√™nea
    """
    logging.info(f"üîÑ Carregando grafo HETEROG√äNEO {graph_type.upper()} de: {file_path}")
    logging.info(f"üìê Knowledge Graph Framework: estrutura heterog√™nea multi-relacional")
    
    # Verifica se o arquivo existe
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Arquivo de grafo heterog√™neo n√£o encontrado: {file_path}")
    
    # Carrega o objeto PyTorch HeteroData
    try:
        # PyTorch 2.6+ precisa de weights_only=False para HeteroData
        data = torch.load(file_path, map_location=device, weights_only=False)
        logging.info(f"‚úÖ Grafo heterog√™neo carregado com sucesso!")
    except Exception as e:
        raise RuntimeError(f"Erro ao carregar grafo heterog√™neo: {str(e)}")
    
    # Verifica se as m√°scaras de divis√£o est√£o presentes nos n√≥s de transa√ß√£o
    required_masks = ['train_mask', 'val_mask', 'test_mask']
    missing_masks = [mask for mask in required_masks if not hasattr(data['transaction'], mask)]
    if missing_masks:
        raise ValueError(f"M√°scaras de divis√£o ausentes nos n√≥s de transa√ß√£o: {missing_masks}")
    
    # Verifica estrutura b√°sica do grafo heterog√™neo
    if 'transaction' not in data.node_types:
        raise ValueError("N√≥s de transa√ß√£o ausentes no grafo heterog√™neo")
    if not hasattr(data['transaction'], 'x') or not hasattr(data['transaction'], 'y'):
        raise ValueError("Features (x) ou labels (y) ausentes nos n√≥s de transa√ß√£o")
    
    # Move dados para o device especificado se necess√°rio
    if data['transaction'].x.device != device:
        data = data.to(device)
        logging.info(f"üì± Grafo movido para device: {device}")
    
    # Log das informa√ß√µes do grafo heterog√™neo
    logging.info(f"üìä Grafo HETEROG√äNEO carregado:")
    logging.info(f"  - Tipos de n√≥s: {len(data.node_types)}")
    for node_type in data.node_types:
        logging.info(f"    * {node_type}: {data[node_type].num_nodes:,} n√≥s")
    
    logging.info(f"  - Tipos de arestas: {len(data.edge_types)}")
    total_edges = 0
    for edge_type in data.edge_types:
        # Verifica diferentes formas de acesso √†s arestas
        edge_count = 0
        if edge_type in data.edge_index_dict:
            edge_count = data.edge_index_dict[edge_type].size(1)
        elif hasattr(data[edge_type], 'edge_index'):
            edge_count = data[edge_type].edge_index.size(1)
            
        total_edges += edge_count
        logging.info(f"    * {edge_type}: {edge_count:,} arestas")
    logging.info(f"  - Total de arestas: {total_edges:,}")
    
    # Features dos n√≥s de transa√ß√£o
    logging.info(f"  - Features por n√≥ de transa√ß√£o: {data['transaction'].x.shape[1]}")
    logging.info(f"  - Device: {data['transaction'].x.device}")
    
    # Log das m√°scaras de divis√£o (apenas n√≥s de transa√ß√£o)
    logging.info(f"üé≠ M√°scaras de divis√£o (n√≥s de transa√ß√£o):")
    logging.info(f"  - Treino: {data['transaction'].train_mask.sum():,} n√≥s ({100*data['transaction'].train_mask.sum()/data['transaction'].num_nodes:.1f}%)")
    logging.info(f"  - Valida√ß√£o: {data['transaction'].val_mask.sum():,} n√≥s ({100*data['transaction'].val_mask.sum()/data['transaction'].num_nodes:.1f}%)")
    logging.info(f"  - Teste: {data['transaction'].test_mask.sum():,} n√≥s ({100*data['transaction'].test_mask.sum()/data['transaction'].num_nodes:.1f}%)")
    
    # Verifica integridade das m√°scaras
    total_masked = data['transaction'].train_mask.sum() + data['transaction'].val_mask.sum() + data['transaction'].test_mask.sum()
    if total_masked != data['transaction'].num_nodes:
        logging.warning(f"‚ö†Ô∏è Sobreposi√ß√£o ou lacunas nas m√°scaras detectadas: {total_masked}/{data['transaction'].num_nodes}")
    
    # Verifica distribui√ß√£o de classes por split
    for split_name, mask in [('Treino', data['transaction'].train_mask), ('Valida√ß√£o', data['transaction'].val_mask), ('Teste', data['transaction'].test_mask)]:
        if mask.sum() > 0:
            split_labels = data['transaction'].y[mask]
            class_counts = torch.bincount(split_labels)
            if len(class_counts) >= 2:
                logging.info(f"  {split_name}: Normal={class_counts[0]}, Fraude={class_counts[1]} "
                           f"(Taxa fraude: {100*class_counts[1]/mask.sum():.2f}%)")
    
    logging.info(f"üî¨ Grafo heterog√™neo: 6 camadas de conectividade multi-relacional para aprendizado estrutural avan√ßado")
    
    return data


class RGCNModel(nn.Module):
    """
    Relational Graph Convolutional Network (R-GCN) para grafos heterog√™neos.
    
    METODOLOGIA KNOWLEDGE GRAPH HETEROG√äNEO:
    - Processa diferentes tipos de relacionamentos (7 tipos de arestas)
    - Agrega√ß√£o por tipo de rela√ß√£o com pesos espec√≠ficos
    - Foco nos n√≥s de transa√ß√£o como sa√≠da principal
    """
    
    def __init__(self, data: HeteroData, hidden_channels: int = 64, out_channels: int = 1, 
                 num_layers: int = 2, dropout: float = 0.3):
        super(RGCNModel, self).__init__()
        
        self.num_relations = len(data.edge_types)
        self.num_layers = num_layers
        self.dropout = dropout
        self.hidden_channels = hidden_channels
        
        # Salva metadados do grafo heterog√™neo para o forward pass
        self.node_types = data.node_types
        self.edge_types = data.edge_types
        
        # Mapeamento de tipos de n√≥s para seus √≠ndices no grafo homog√™neo global
        self.node_type_offset = {}
        cumulative_nodes = 0
        for node_type in data.node_types:
            self.node_type_offset[node_type] = cumulative_nodes
            cumulative_nodes += data[node_type].num_nodes
        
        self.total_nodes = cumulative_nodes
        
        # Projeta diferentes tipos de n√≥s para o mesmo espa√ßo dimensional
        self.node_embeddings = nn.ModuleDict()
        for node_type in data.node_types:
            if hasattr(data[node_type], 'x') and data[node_type].x is not None:
                node_in_channels = data[node_type].x.shape[1]
                self.node_embeddings[node_type] = nn.Linear(node_in_channels, hidden_channels)
            else:
                # Para n√≥s sem features, cria embeddings aprend√≠veis
                self.node_embeddings[node_type] = nn.Embedding(data[node_type].num_nodes, hidden_channels)
        
        logging.info(f"üîß R-GCN KNOWLEDGE: total_nodes={self.total_nodes}, relations={self.num_relations}")
        logging.info(f"   Node types: {list(self.node_types)}")
        logging.info(f"   Edge types: {list(self.edge_types)}")
        
        # Camadas R-GCN operando no espa√ßo homog√™neo unificado
        self.convs = nn.ModuleList()
        self.convs.append(RGCNConv(hidden_channels, hidden_channels, self.num_relations))
        
        for _ in range(num_layers - 1):
            self.convs.append(RGCNConv(hidden_channels, hidden_channels, self.num_relations))
        
        # Normaliza√ß√µes
        self.norms = nn.ModuleList([
            nn.LayerNorm(hidden_channels) for _ in range(num_layers)
        ])
        
        # Classificador final - projeta apenas n√≥s de transa√ß√£o para a sa√≠da
        self.classifier = nn.Sequential(
            nn.Linear(hidden_channels, hidden_channels // 2),
            nn.LayerNorm(hidden_channels // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_channels // 2, out_channels)
        )
        
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight, gain=0.5)  # Gain reduzido para estabilidade
            if module.bias is not None:
                nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Embedding):
            nn.init.normal_(module.weight, mean=0.0, std=0.1)  # Embedding mais conservador
    
    def forward(self, data: HeteroData) -> torch.Tensor:
        """
        Forward pass para R-GCN heterog√™neo.
        Processa TODOS os tipos de n√≥s e arestas do grafo de conhecimento.
        Retorna logits apenas para n√≥s de transa√ß√£o.
        """
        device = next(self.parameters()).device
        
        # PASSO 1: Projeta todos os tipos de n√≥s para o espa√ßo dimensional unificado
        all_node_embeddings = []
        
        for node_type in self.node_types:
            if hasattr(data[node_type], 'x') and data[node_type].x is not None:
                # N√≥s com features: projeta para espa√ßo hidden
                features = data[node_type].x
                # Normaliza√ß√£o simples para estabilidade
                features = torch.clamp(features, min=-10.0, max=10.0)
                node_emb = self.node_embeddings[node_type](features)
            else:
                # N√≥s sem features: usa embeddings aprend√≠veis
                num_nodes = data[node_type].num_nodes
                node_indices = torch.arange(num_nodes, device=device)
                node_emb = self.node_embeddings[node_type](node_indices)
            
            all_node_embeddings.append(node_emb)
        
        # PASSO 2: Concatena todos os n√≥s em um √∫nico tensor homog√™neo
        x_unified = torch.cat(all_node_embeddings, dim=0)  # Shape: [total_nodes, hidden_channels]
        
        # PASSO 3: Converte todas as arestas heterog√™neas para formato homog√™neo global
        all_edges = []
        all_edge_types = []
        
        for relation_idx, edge_type in enumerate(self.edge_types):
            src_type, relation, dst_type = edge_type
            
            # Tenta diferentes formas de acessar as arestas
            edge_index = None
            try:
                if hasattr(data, 'edge_index_dict') and edge_type in data.edge_index_dict:
                    edge_index = data.edge_index_dict[edge_type]
                elif hasattr(data[edge_type], 'edge_index'):
                    edge_index = data[edge_type].edge_index
                else:
                    continue
            except (KeyError, AttributeError):
                continue
            
            if edge_index is None or edge_index.size(1) == 0:
                continue
            
            # Converte √≠ndices locais para √≠ndices globais
            src_offset = self.node_type_offset[src_type]
            dst_offset = self.node_type_offset[dst_type]
            
            global_edge_index = edge_index.clone()
            global_edge_index[0] += src_offset  # Source nodes
            global_edge_index[1] += dst_offset  # Destination nodes
            
            all_edges.append(global_edge_index)
            all_edge_types.extend([relation_idx] * edge_index.size(1))
        
        # PASSO 4: Combina todas as arestas em formato homog√™neo
        if all_edges:
            combined_edge_index = torch.cat(all_edges, dim=1)
            combined_edge_type = torch.tensor(all_edge_types, dtype=torch.long, device=device)
            
            logging.debug(f"üîó Processando {len(all_edges)} tipos de arestas, "
                         f"total {combined_edge_index.size(1):,} arestas")
        else:
            # Fallback: criar auto-loops para todos os n√≥s
            logging.warning("‚ö†Ô∏è Nenhuma aresta encontrada, criando auto-loops")
            combined_edge_index = torch.stack([
                torch.arange(self.total_nodes, device=device),
                torch.arange(self.total_nodes, device=device)
            ], dim=0)
            combined_edge_type = torch.zeros(self.total_nodes, dtype=torch.long, device=device)
        
        # PASSO 5: Passagem pelas camadas R-GCN no espa√ßo homog√™neo unificado
        x = x_unified
        for i, conv in enumerate(self.convs):
            x = conv(x, combined_edge_index, combined_edge_type)
            x = self.norms[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
            
            # Verifica√ß√£o de estabilidade num√©rica
            if torch.isnan(x).any() or torch.isinf(x).any():
                logging.warning(f"‚ö†Ô∏è NaN/Inf detectado na camada R-GCN {i}. Aplicando corre√ß√£o.")
                x = torch.nan_to_num(x, nan=0.0, posinf=1.0, neginf=-1.0)
        
        # PASSO 6: Extrai apenas os embeddings dos n√≥s de transa√ß√£o para classifica√ß√£o
        transaction_offset = self.node_type_offset['transaction']
        transaction_end = transaction_offset + data['transaction'].num_nodes
        transaction_embeddings = x[transaction_offset:transaction_end]
        
        # PASSO 7: Classifica√ß√£o final apenas para n√≥s de transa√ß√£o
        logits = self.classifier(transaction_embeddings)
        
        # Verifica√ß√£o final de estabilidade
        if torch.isnan(logits).any() or torch.isinf(logits).any():
            logging.warning("‚ö†Ô∏è NaN/Inf detectado nos logits finais. Aplicando corre√ß√£o.")
            logits = torch.nan_to_num(logits, nan=0.0, posinf=5.0, neginf=-5.0)
        
        return logits


def validate_real_graph_data(data: HeteroData) -> bool:
    """
    Valida que os dados do grafo s√£o reais e √≠ntegros para experimentos cient√≠ficos.
    
    METODOLOGIA CIENT√çFICA:
    - Verifica integridade dos dados sem criar dados artificiais
    - Garante que todos os tipos de n√≥s t√™m features reais
    - Valida que os √≠ndices das arestas s√£o consistentes
    
    Args:
        data (HeteroData): Dados do grafo heterog√™neo
        
    Returns:
        bool: True se os dados s√£o v√°lidos para experimentos cient√≠ficos
    """
    logging.info("üî¨ Validando integridade dos dados reais do grafo...")
    
    # Verificar se os tipos de n√≥s t√™m estrutura v√°lida
    for node_type in data.node_types:
        # Alguns tipos de n√≥s podem n√£o ter features (ex: temporal, product)
        # O modelo criar√° embeddings aprend√≠veis para eles
        if hasattr(data[node_type], 'x') and data[node_type].x is not None:
            if data[node_type].x.size(0) != data[node_type].num_nodes:
                logging.error(f"‚ùå ERRO CIENT√çFICO: Inconsist√™ncia em {node_type}: {data[node_type].x.size(0)} features vs {data[node_type].num_nodes} n√≥s")
                return False
            logging.info(f"‚úÖ {node_type}: {data[node_type].num_nodes:,} n√≥s com {data[node_type].x.shape[1]} features")
        else:
            logging.info(f"‚ÑπÔ∏è {node_type}: {data[node_type].num_nodes:,} n√≥s sem features (usar√° embeddings aprend√≠veis)")
    
    # Verificar integridade dos √≠ndices das arestas
    valid_edge_types = 0
    for edge_type in data.edge_types:
        src_type, relation, dst_type = edge_type
        
        # Verifica diferentes formas de acesso √†s arestas
        edge_index = None
        if edge_type in data.edge_index_dict:
            edge_index = data.edge_index_dict[edge_type]
        elif hasattr(data[edge_type], 'edge_index'):
            edge_index = data[edge_type].edge_index
        
        if edge_index is None or edge_index.size(1) == 0:
            logging.warning(f"‚ö†Ô∏è {edge_type}: Nenhuma aresta encontrada")
            continue
            
        valid_edge_types += 1
        max_src_idx = edge_index[0].max().item()
        max_dst_idx = edge_index[1].max().item()
        
        if max_src_idx >= data[src_type].num_nodes:
            logging.error(f"‚ùå ERRO CIENT√çFICO: √çndice de origem inv√°lido em {edge_type}: {max_src_idx} >= {data[src_type].num_nodes}")
            return False
            
        if max_dst_idx >= data[dst_type].num_nodes:
            logging.error(f"‚ùå ERRO CIENT√çFICO: √çndice de destino inv√°lido em {edge_type}: {max_dst_idx} >= {data[dst_type].num_nodes}")
            return False
            
        logging.info(f"‚úÖ {edge_type}: {edge_index.size(1):,} arestas v√°lidas")
    
    if valid_edge_types == 0:
        logging.error("‚ùå ERRO CIENT√çFICO: Nenhum tipo de aresta v√°lido encontrado")
        return False
    
    logging.info(f"‚úÖ Dados do grafo validados - {valid_edge_types} tipos de arestas v√°lidos - Integridade cient√≠fica confirmada")
    return True


def ensure_model_reproducibility(model: nn.Module, model_name: str, model_seed: int) -> None:
    """
    Garante reprodutibilidade cient√≠fica com inicializa√ß√µes padr√£o para R-GCN.
    
    Args:
        model (nn.Module): Modelo R-GCN a ser inicializado
        model_name (str): Nome do modelo para logging
        model_seed (int): Seed determin√≠stico para reprodutibilidade
    """
    # üî¨ SEED CIENT√çFICO UNIFICADO
    # Usa o seed global definido sem modifica√ß√£o
    # que apenas a estrutura do grafo influencie os resultados
    init_seed = model_seed
    
    # Define todos os seeds para garantir reprodutibilidade total
    torch.manual_seed(init_seed)
    np.random.seed(init_seed)
    random.seed(init_seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(init_seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
        
    logging.info(f"üî¢ Seed cient√≠fico fixo para {model_name}: {init_seed}")
    
    # üîß INICIALIZA√á√ÉO T√âCNICA: R-GCN n√£o precisa de forward pass especial
    # Aplica√ß√µes de inicializa√ß√µes padr√£o recomendadas pela literatura cient√≠fica
    
    # Aplica inicializa√ß√µes padr√£o recomendadas pela literatura cient√≠fica
    # Sem varia√ß√µes para garantir compara√ß√£o cient√≠fica justa
    with torch.no_grad():
        for name, param in model.named_parameters():
            # Verifica se o par√¢metro est√° inicializado (evita erro com LazyModules n√£o inicializados)
            if hasattr(param, 'dim'):
                try:
                    param_dim = param.dim()
                except:
                    # Skip par√¢metros n√£o inicializados
                    continue
                    
                if 'weight' in name and param_dim >= 2:
                    # Inicializa√ß√µes cient√≠ficas padr√£o por arquitetura heterog√™nea
                    if 'RGCN' in model_name:
                        # R-GCN: Xavier/Glorot uniform (Schlichtkrull et al., 2018)
                        nn.init.xavier_uniform_(param, gain=1.0)
                    else:
                        # Padr√£o: Xavier uniform para modelos heterog√™neos
                        nn.init.xavier_uniform_(param, gain=1.0)
                            
                elif 'bias' in name and param is not None:
                    # üî¨ SEED CIENT√çFICO: Inicializa√ß√£o consistente de bias para reprodutibilidade
                    # Usa zeros para todos os modelos, garantindo inicializa√ß√£o id√™ntica
                    nn.init.zeros_(param)  # Padr√£o cient√≠fico comum


def train_one_epoch(model: nn.Module, data: HeteroData, optimizer: torch.optim.Optimizer, 
                   criterion: nn.Module, class_weights: torch.Tensor, epoch: int, total_epochs: int,
                   scaler: torch.amp.GradScaler = None, model_name: str = "Model", 
                   graph_type: str = "knowledge", split_mask: torch.Tensor = None) -> Tuple[float, Dict[str, float]]:
    """
    Executa uma √∫nica √©poca de treinamento com suporte a grafos heterog√™neos.
    
    Args:
        model (nn.Module): Modelo a ser treinado
        data (HeteroData): Dados completos do grafo heterog√™neo
        optimizer (torch.optim.Optimizer): Otimizador
        criterion (nn.Module): Fun√ß√£o de perda
        class_weights (torch.Tensor): Pesos das classes para balanceamento
        epoch (int): √âpoca atual
        total_epochs (int): Total de √©pocas
        scaler: GradScaler para mixed precision
        model_name (str): Nome do modelo para otimiza√ß√µes espec√≠ficas
        graph_type (str): Tipo de grafo para otimiza√ß√µes espec√≠ficas
        split_mask (torch.Tensor): M√°scara para o split de treinamento (usa train_mask se None)
        
    Returns:
        Tuple[float, Dict[str, float]]: Perda da √©poca e m√©tricas adicionais
    """
    model.train()
    optimizer.zero_grad()
    
    # Define m√°scara de treinamento (apenas n√≥s de transa√ß√£o)
    if split_mask is None:
        if hasattr(data['transaction'], 'train_mask'):
            train_mask = data['transaction'].train_mask
        else:
            # Fallback: usa todos os n√≥s (compatibilidade com grafos legados)
            train_mask = torch.ones(data['transaction'].num_nodes, dtype=torch.bool, device=data['transaction'].x.device)
            logging.warning("‚ö†Ô∏è train_mask n√£o encontrada, usando todos os n√≥s para treinamento")
    else:
        train_mask = split_mask
    
    # Limpeza de cache para modelos de aten√ß√£o heterog√™nea
    is_attention_model = "HAN" in model_name.upper() or "HGT" in model_name.upper()
    if is_attention_model and torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # Mixed precision training se dispon√≠vel
    if scaler is not None:
        with torch.amp.autocast('cuda'):
            out = model(data)
            
            # ÔøΩ CORRE√á√ÉO CR√çTICA: Aplica m√°scara de treinamento ANTES de qualquer c√°lculo
            out_masked = out[train_mask].squeeze()
            targets_masked = data['transaction'].y[train_mask].float()
            
            # Verifica se h√° dados suficientes para treinamento
            if out_masked.numel() == 0 or targets_masked.numel() == 0:
                logging.warning("‚ö†Ô∏è Nenhum dado de treinamento dispon√≠vel. Pulando √©poca.")
                return 0.0, {}
            
            # Peso positivo baseado na distribui√ß√£o de classes NO CONJUNTO DE TREINO
            train_class_counts = torch.bincount(targets_masked.long())
            if len(train_class_counts) >= 2 and train_class_counts[1] > 0:
                pos_weight = torch.clamp(train_class_counts[0].float() / train_class_counts[1].float(), min=1.0, max=100.0)
            else:
                pos_weight = torch.tensor(25.0, device=data['transaction'].x.device)
            
            # üî¨ FOCAL LOSS CIENT√çFICO - Par√¢metros fixos constantes cient√≠ficas
            alpha = 0.25  # Valor cient√≠fico fixo para todos os modelos (literatura padr√£o)
            gamma = 2.0   # Valor cient√≠fico fixo para todos os modelos (literatura padr√£o)
            
            # BCE Loss com clipping para estabilidade num√©rica - APLICADO APENAS AOS DADOS DE TREINO
            out_clamped = torch.clamp(out_masked, min=-10.0, max=10.0)
            
            # Verifica√ß√£o pr√©via de NaN nos outputs
            if torch.isnan(out_clamped).any() or torch.isinf(out_clamped).any():
                logging.warning("‚ö†Ô∏è NaN/Inf detectado nos outputs do modelo. Aplicando corre√ß√£o.")
                out_clamped = torch.nan_to_num(out_clamped, nan=0.0, posinf=5.0, neginf=-5.0)
            
            bce_loss = F.binary_cross_entropy_with_logits(
                out_clamped, targets_masked, pos_weight=pos_weight, reduction='none'
            )
            
            # Verifica√ß√£o de NaN no BCE loss
            if torch.isnan(bce_loss).any() or torch.isinf(bce_loss).any():
                logging.warning("‚ö†Ô∏è NaN/Inf detectado no BCE loss. Usando BCE simples.")
                focal_loss = F.binary_cross_entropy_with_logits(out_clamped, targets_masked, pos_weight=pos_weight)
            else:
                # Probabilidades com estabiliza√ß√£o num√©rica
                probs = torch.sigmoid(out_clamped)
                probs = torch.clamp(probs, min=1e-7, max=1-1e-7)
                
                # C√°lculo focal weight com exponencial est√°vel
                focal_weight_pos = torch.pow(1 - probs + 1e-8, gamma)
                focal_weight_neg = torch.pow(probs + 1e-8, gamma)
                
                focal_weight = torch.where(
                    targets_masked == 1, 
                    focal_weight_pos,
                    focal_weight_neg
                )
                
                # Alpha balancing
                alpha_weight = torch.where(targets_masked == 1, alpha, 1 - alpha)
                
                # Combina pesos com clipping adequado
                final_weight = torch.clamp(focal_weight * alpha_weight, min=1e-8, max=25.0)
                focal_loss = (final_weight * bce_loss).mean()
                
                # Verifica√ß√£o final de NaN no focal loss
                if torch.isnan(focal_loss) or torch.isinf(focal_loss):
                    logging.warning("‚ö†Ô∏è NaN/Inf no focal loss. Fallback para BCE.")
                    focal_loss = F.binary_cross_entropy_with_logits(out_clamped, targets_masked, pos_weight=pos_weight)
            
            # Calcula m√©tricas r√°pidas se focal loss √© v√°lido
            if not (torch.isnan(focal_loss) or torch.isinf(focal_loss)):
                with torch.no_grad():
                    probs_eval = torch.sigmoid(out_clamped)
                    preds = (probs_eval > 0.5).long()
                    
                    # M√©tricas b√°sicas para classes desbalanceadas
                    y_true = targets_masked.cpu().numpy()
                    y_pred = preds.cpu().numpy()
                    y_probs = probs_eval.cpu().numpy()
                    
                    if len(np.unique(y_true)) > 1 and not np.isnan(y_probs).any():
                        try:
                            auc_roc = roc_auc_score(y_true, y_probs)
                            auc_pr = average_precision_score(y_true, y_probs)
                            
                            if len(np.unique(y_pred)) > 1:
                                recall = recall_score(y_true, y_pred, zero_division=0)
                                precision = precision_score(y_true, y_pred, zero_division=0)
                                f2 = fbeta_score(y_true, y_pred, beta=2, zero_division=0)
                            else:
                                recall = precision = f2 = 0.0
                            
                            logging.info(f"üìä √âpoca {epoch}: AUC-ROC={auc_roc:.4f}, AUC-PR={auc_pr:.4f}, F2={f2:.4f}, Recall={recall:.4f}, Precision={precision:.4f}")
                        except Exception as e:
                            logging.warning(f"üìä √âpoca {epoch}: Erro no c√°lculo de m√©tricas: {str(e)}")
                            logging.info(f"üìä √âpoca {epoch}: Focal‚ÜíBCE fallback (erro: {type(e).__name__})")
                    else:
                        logging.info(f"üìä √âpoca {epoch}: Focal‚ÜíBCE fallback (dados insuficientes)")
            
            # Regulariza√ß√£o L2 com prote√ß√£o contra overflow
            l2_reg = 0
            for param in model.parameters():
                if param.requires_grad:
                    param_norm = torch.norm(param, p=2)
                    if torch.isfinite(param_norm):
                        l2_reg += param_norm
            
            # Perda total com clipping final
            reg_strength = 1e-5 * (1 - epoch / total_epochs)  # Reduzido de 1e-4
            total_loss = focal_loss + reg_strength * l2_reg
            total_loss = torch.clamp(total_loss, min=1e-8, max=100.0)
        
        # Backward pass com scaler
        scaler.scale(total_loss).backward()
        scaler.unscale_(optimizer)
        
        # Gradient clipping adaptativo
        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        scaler.step(optimizer)
        scaler.update()
    else:
        # Treinamento sem mixed precision
        out = model(data)
        
        # üìã CORRE√á√ÉO CR√çTICA: Aplica m√°scara de treinamento aos outputs e targets
        out_masked = out[train_mask].squeeze()
        targets_masked = data['transaction'].y[train_mask].float()
        
        # Verifica se h√° dados suficientes para treinamento
        if out_masked.numel() == 0 or targets_masked.numel() == 0:
            logging.warning("‚ö†Ô∏è Nenhum dado de treinamento dispon√≠vel. Pulando √©poca.")
            return 0.0, {}
        
        # Peso positivo baseado na distribui√ß√£o de classes NO CONJUNTO DE TREINO
        train_class_counts = torch.bincount(targets_masked.long())
        if len(train_class_counts) >= 2 and train_class_counts[1] > 0:
            pos_weight = torch.clamp(train_class_counts[0].float() / train_class_counts[1].float(), min=1.0, max=100.0)
        else:
            pos_weight = torch.tensor(25.0, device=data['transaction'].x.device)
        
        # Verifica√ß√£o pr√©via de NaN nos outputs
        if torch.isnan(out_masked).any() or torch.isinf(out_masked).any():
            logging.warning("‚ö†Ô∏è NaN/Inf detectado nos outputs do modelo. Aplicando corre√ß√£o.")
            out_masked = torch.nan_to_num(out_masked, nan=0.0, posinf=5.0, neginf=-5.0)
        
        # Clipping para evitar problemas num√©ricos
        out_clamped = torch.clamp(out_masked, min=-10, max=10)
        
        # BCE Loss com peso positivo
        bce_loss = F.binary_cross_entropy_with_logits(
            out_clamped, targets_masked, pos_weight=pos_weight, reduction='none'
        )
        
        # Focal Loss parameters - cient√≠ficos padr√£o
        alpha = 0.25
        gamma = 2.0
        
        # Verifica se BCE loss √© v√°lido
        if torch.isnan(bce_loss).any() or torch.isinf(bce_loss).any():
            logging.warning("‚ö†Ô∏è NaN/Inf detectado no BCE loss. Usando BCE simples.")
            focal_loss = F.binary_cross_entropy_with_logits(out_clamped, targets_masked, pos_weight=pos_weight)
        else:
            # Calcula focal weights
            pt = torch.sigmoid(out_clamped)
            pt = torch.clamp(pt, min=1e-7, max=1-1e-7)
            
            focal_weight_pos = alpha * torch.pow(1 - pt + 1e-8, gamma)
            focal_weight_neg = (1 - alpha) * torch.pow(pt + 1e-8, gamma)
            
            focal_weight = torch.where(
                targets_masked == 1, 
                focal_weight_pos,
                focal_weight_neg
            )
            
            # Combina pesos com clipping adequado
            final_weight = torch.clamp(focal_weight, min=1e-8, max=25.0)
            focal_loss = (final_weight * bce_loss).mean()
            
            # Verifica NaN/Inf e fallback se necess√°rio
            if torch.isnan(focal_loss) or torch.isinf(focal_loss):
                logging.warning(f"‚ö†Ô∏è Loss inv√°lido detectado na √©poca {epoch+1}. Usando BCE padr√£o.")
                focal_loss = F.binary_cross_entropy_with_logits(out_clamped, targets_masked, pos_weight=pos_weight)
        
        # L2 regularization estabilizada
        l2_reg = 0
        for param in model.parameters():
            if param.requires_grad:
                param_norm = torch.norm(param, 2)
                if torch.isfinite(param_norm):
                    l2_reg += param_norm
                
        reg_strength = 1e-5 * (1 - epoch / total_epochs)
        total_loss = focal_loss + reg_strength * l2_reg
        total_loss = torch.clamp(total_loss, min=1e-8, max=100.0)
        
        total_loss.backward()
        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
    
    # Limpeza adicional de cache ap√≥s backward pass para modelos de aten√ß√£o heterog√™nea
    if is_attention_model and torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # Calcula m√©tricas de treinamento usando apenas dados de treino
    with torch.no_grad():
        probs = torch.sigmoid(out[train_mask].squeeze())
        
        # Verificar NaN nas probabilidades
        if torch.isnan(probs).any() or torch.isinf(probs).any():
            logging.warning("‚ö†Ô∏è NaN/Inf detectado nas probabilidades de treino")
            probs = torch.nan_to_num(probs, nan=0.5, posinf=0.99, neginf=0.01)
        
        y_true = data['transaction'].y[train_mask].cpu().numpy()
        y_probs = probs.cpu().numpy()
        
        # Verificar NaN nos arrays numpy
        if np.isnan(y_probs).any() or np.isinf(y_probs).any():
            logging.warning("‚ö†Ô∏è NaN/Inf detectado em y_probs")
            y_probs = np.nan_to_num(y_probs, nan=0.5, posinf=0.99, neginf=0.01)
        
        # Threshold simples para m√©tricas r√°pidas durante treino
        y_pred = (y_probs > 0.5).astype(int)
        
        # Calcular m√©tricas com tratamento de erro
        try:
            train_recall = recall_score(y_true, y_pred, zero_division=0)
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Erro no c√°lculo de recall: {str(e)}")
            train_recall = 0.0
        
        train_metrics = {
            'focal_loss': focal_loss.item(),
            'l2_reg': l2_reg.item() if isinstance(l2_reg, torch.Tensor) else l2_reg,
            'grad_norm': grad_norm.item(),
            'train_recall': train_recall,
            'positive_samples': int(data['transaction'].y[train_mask].sum().item()),
            'mean_positive_prob': float(probs[data['transaction'].y[train_mask] == 1].mean().item()) if (data['transaction'].y[train_mask] == 1).sum() > 0 else 0.0,
            'mean_negative_prob': float(probs[data['transaction'].y[train_mask] == 0].mean().item()) if (data['transaction'].y[train_mask] == 0).sum() > 0 else 0.0
        }
    
    return total_loss.item(), train_metrics


def evaluate_model(model: nn.Module, data: HeteroData, calibrate_probs: bool = True,
                  graph_type: str = "knowledge", split_mask: torch.Tensor = None) -> Dict[str, float]:
    """
    Avalia o desempenho do modelo com calibra√ß√£o avan√ßada de probabilidades e m√°scaras de split para grafos heterog√™neos.
    
    Args:
        model (nn.Module): Modelo treinado
        data (HeteroData): Dados completos do grafo heterog√™neo
        calibrate_probs (bool): Se deve aplicar calibra√ß√£o de probabilidade
        graph_type (str): Tipo de grafo para otimiza√ß√µes espec√≠ficas
        split_mask (torch.Tensor): M√°scara para o split de avalia√ß√£o (usa todos os n√≥s se None)
        
    Returns:
        Dict[str, float]: Dicion√°rio com m√©tricas de avalia√ß√£o abrangentes
    """
    model.eval()
    
    # üîç VERIFICA√á√ÉO CR√çTICA: Garantia de que modelo est√° realmente no modo eval
    if model.training:
        logging.warning("‚ö†Ô∏è Modelo ainda em modo training! For√ßando eval()...")
        model.eval()
    
    with torch.no_grad():
        # Define m√°scara de avalia√ß√£o (apenas n√≥s de transa√ß√£o)
        if split_mask is None:
            # Fallback: usa todos os n√≥s de transa√ß√£o (compatibilidade com grafos legados)
            eval_mask = torch.ones(data['transaction'].num_nodes, dtype=torch.bool, device=data['transaction'].x.device)
        else:
            eval_mask = split_mask
            
        # üìù SEED CIENT√çFICO FIXO PARA AVALIA√á√ÉO
        # Usa o mesmo seed global para todas as avalia√ß√µes de modelo
        # garantindo que diferen√ßas nos resultados venham apenas da estrutura do grafo
        
        inference_seed = SCIENTIFIC_SEED  # Usa o seed cient√≠fico global
        
        # Aplica seed cient√≠fico a todas as bibliotecas para completa reprodutibilidade
        np.random.seed(inference_seed)
        torch.manual_seed(inference_seed)
        random.seed(inference_seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(inference_seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
            
        logging.debug(f"üî¨ Seed cient√≠fico fixo para avalia√ß√£o de todos os modelos: {inference_seed}")
        
        # Forward pass
        logits = model(data)
        
        # Aplica sigmoid para obter probabilidades
        probs = torch.sigmoid(logits.squeeze())
        
        # üîß CORRE√á√ÉO CR√çTICA: Aplica m√°scara de avalia√ß√£o aos dados
        probs_masked = probs[eval_mask]
        y_true_masked = data['transaction'].y[eval_mask]
        
        # Move para CPU e converte para numpy
        y_true = y_true_masked.cpu().numpy()
        y_probs = probs_masked.cpu().numpy()
        
        # üîç VERIFICA√á√ÉO CIENT√çFICA: Detecta probabilidades suspeitas ou id√™nticas
        prob_std = np.std(y_probs)
        prob_mean = np.mean(y_probs)
        prob_min = np.min(y_probs)
        prob_max = np.max(y_probs)
        
        if prob_std < 1e-5:
            logging.error("üö® ERRO CR√çTICO: Probabilidades muito uniformes!")
            logging.error("Isso indica poss√≠vel bug no modelo ou dados corrompidos!")
            
        # üîç VERIFICA√á√ÉO CIENT√çFICA: Sem adi√ß√£o de ru√≠do artificial
        # Mant√©m probabilidades originais do modelo para an√°lise cient√≠fica v√°lida
        # Qualquer varia√ß√£o deve vir naturalmente das diferen√ßas arquiteturais
        
        # Calibra√ß√£o de probabilidade usando Platt Scaling (isotonic regression)
        if calibrate_probs and len(np.unique(y_true)) > 1:
            from sklearn.calibration import CalibratedClassifierCV
            from sklearn.base import BaseEstimator, ClassifierMixin
            
            class DummyClassifier(BaseEstimator, ClassifierMixin):
                def __init__(self, probs):
                    self.probs = probs
                def predict_proba(self, X):
                    return np.column_stack([1 - self.probs, self.probs])
                def fit(self, X, y):
                    return self
            
            dummy_clf = DummyClassifier(y_probs)
            
            try:
                # Aplica calibra√ß√£o se h√° amostras suficientes
                if len(y_true) >= 20 and y_true.sum() >= 3:
                    calibrated_clf = CalibratedClassifierCV(dummy_clf, method="isotonic", cv=3)
                    X_dummy = np.zeros((len(y_true), 1))  # Features dummy
                    calibrated_clf.fit(X_dummy, y_true)
                    calibrated_probs = calibrated_clf.predict_proba(X_dummy)[:, 1]
                    y_probs_cal = calibrated_probs
                else:
                    y_probs_cal = y_probs
            except:
                y_probs_cal = y_probs
        else:
            y_probs_cal = y_probs
        
        # Otimiza√ß√£o de threshold usando m√∫ltiplas estrat√©gias
        precision, recall, thresholds = precision_recall_curve(y_true, y_probs_cal)
        
        # Estrat√©gia 1: Maximizar F1-Score - peso equilibrado precision/recall
        f1_scores = (2 * precision * recall) / (precision + recall + 1e-10)
        best_f1_idx = np.argmax(f1_scores)
        f1_optimal_threshold = thresholds[best_f1_idx] if best_f1_idx < len(thresholds) else 0.5
        
        # Estrat√©gia 2: Maximizar F2-Score para compatibilidade
        f2_scores = (5 * precision * recall) / (4 * precision + recall + 1e-10)
        best_f2_idx = np.argmax(f2_scores)
        f2_optimal_threshold = thresholds[best_f2_idx] if best_f2_idx < len(thresholds) else 0.5
        
        # Estrat√©gia 3: Threshold por percentil das probabilidades positivas - mais agressivo
        if y_true.sum() > 0:
            pos_probs = y_probs_cal[y_true == 1]
            # Ajustado para melhor balance precision/recall
            percentile_threshold = np.percentile(pos_probs, 5)  # Menos agressivo que 1
        else:
            percentile_threshold = 0.2  # Menos agressivo que 0.1
        
        # Estrat√©gia 4: Youden's J statistic (sensibilidade + especificidade - 1)
        from sklearn.metrics import roc_curve
        fpr, tpr, roc_thresholds = roc_curve(y_true, y_probs_cal)
        youden_j = tpr - fpr
        best_youden_idx = np.argmax(youden_j)
        youden_threshold = roc_thresholds[best_youden_idx]
        
        # Estrat√©gia 5: Threshold otimizado para balancear precision e recall
        # Ajustado para equil√≠brio entre recall e precision
        min_recall_target = 0.78  # Aumentado para for√ßar recall mais alto mas equilibrado
        recall_thresholds = []
        
        # Busca de thresholds candidatos em faixa balanceada
        for thresh in np.linspace(0.05, 0.5, 150):  # Faixa menos agressiva
            y_pred_temp = (y_probs_cal > thresh).astype(int)
            if len(np.unique(y_pred_temp)) > 1:
                recall_temp = recall_score(y_true, y_pred_temp, zero_division=0)
                if recall_temp >= min_recall_target:
                    precision_temp = precision_score(y_true, y_pred_temp, zero_division=0)
                    recall_thresholds.append((thresh, recall_temp, precision_temp))
        
        # Seleciona o threshold com maior valor (mais restritivo) que mant√©m recall adequado
        recall_threshold = 0.2  # valor padr√£o menos agressivo
        if recall_thresholds:
            # Ordena por threshold (decrescente) e pega o primeiro (maior) que atende crit√©rio
            recall_thresholds.sort(reverse=True)
            recall_threshold = recall_thresholds[0][0]
        
        # Estrat√©gia adicional: Threshold baseado na propor√ß√£o de fraudes (menos agressivo)
        fraud_ratio = np.mean(y_true)  # ~0.014 para este dataset
        # Threshold baseado em quantil das probabilidades (menos agressivo)
        ratio_threshold = np.quantile(y_probs_cal, 1 - fraud_ratio * 2)  # 2x em vez de 3x
        
        # Escolhe o melhor threshold baseado em m√∫ltiplos crit√©rios
        # Candidatos de threshold incluindo F1 como prioridade
        thresholds_candidates = {
            'f1_optimal': f1_optimal_threshold,    # NOVA prioridade
            'f2_optimal': f2_optimal_threshold,
            'percentile': percentile_threshold,
            'youden': youden_threshold,
            'recall_target': recall_threshold,
            'ratio_based': ratio_threshold
        }
        
        # üî¨ ESTRAT√âGIA DE THRESHOLD EQUILIBRADA F1/F2
        # Prioriza F1 para compara√ß√£o mais justa entre tipos de grafo
        
        # Prioriza F1 seguido de estrat√©gias equilibradas
        priority_strategies = ['f1_optimal', 'recall_target', 'ratio_based', 'f2_optimal', 'percentile', 'youden']
            
        # Threshold padr√£o otimizado para dados desbalanceados
        best_threshold = recall_threshold  # Default - prioriza recall
        best_f2 = 0
        best_metric = 0
        
        # Primeiro tenta as estrat√©gias priorit√°rias
        for strategy in priority_strategies:
            thresh = thresholds_candidates[strategy]
            y_pred_temp = (y_probs_cal > thresh).astype(int)
            if len(np.unique(y_pred_temp)) > 1:  # Evita divis√£o por zero
                recall_temp = recall_score(y_true, y_pred_temp, zero_division=0)
                f1_temp = fbeta_score(y_true, y_pred_temp, beta=1, zero_division=0)
                f2_temp = fbeta_score(y_true, y_pred_temp, beta=2, zero_division=0)
                
                # M√©trica combinada priorizando F1
                combined_metric = 0.6 * f1_temp + 0.4 * f2_temp
                
                if combined_metric > best_metric and f1_temp > 0.1:  # F1 m√≠nimo
                    best_threshold = thresh
                    best_f2 = f2_temp
                    best_metric = combined_metric
                    
        # Se nenhuma estrat√©gia priorit√°ria funcionou bem, testa todas
        if best_f2 < 0.3:  # Valor baixo indica que as priorit√°rias n√£o foram boas
            for name, thresh in thresholds_candidates.items():
                y_pred_temp = (y_probs_cal > thresh).astype(int)
                if len(np.unique(y_pred_temp)) > 1:
                    f2_temp = fbeta_score(y_true, y_pred_temp, beta=2, zero_division=0)
                    if f2_temp > best_f2:
                        best_threshold = thresh
                        best_f2 = f2_temp
        
        # üîç OTIMIZA√á√ÉO DE THRESHOLD CIENT√çFICA: Baseada apenas em m√©tricas estat√≠sticas
        # Remove varia√ß√µes artificiais para manter validade cient√≠fica
        threshold_seed = abs(hash(str(model.__class__.__name__) + str(inference_seed))) % 10000
        np.random.seed(threshold_seed)
        
        # Valida√ß√£o cient√≠fica: verifica se threshold est√° dentro de faixa razo√°vel
        if best_threshold < 0.001 or best_threshold > 0.999:
            logging.warning(f"‚ö†Ô∏è Threshold extremo detectado: {best_threshold:.6f}")
            best_threshold = np.clip(best_threshold, 0.001, 0.999)
        
        # üîß CORRE√á√ÉO CR√çTICA: Usa threshold espec√≠fico DESTE modelo para predi√ß√µes
        y_pred = (y_probs_cal > best_threshold).astype(int)
        
        # üìù SEED CIENT√çFICO: Hash determin√≠stico para verifica√ß√£o consistente
        # Usa soma simples dos primeiros valores em vez do hash Python (mais determin√≠stico)
        prob_hash = int(np.sum(y_probs_cal[:100]) * 1000) % 1000000
        pred_hash = int(np.sum(y_pred[:100]) * 1000) % 1000000
        logging.debug(f"üîç {model.__class__.__name__} - Prob Hash: {prob_hash}, Pred Hash: {pred_hash}, Threshold: {best_threshold:.6f}")
        
        # üö® CORRE√á√ÉO CR√çTICA: AUC-ROC deve usar probabilidades, n√£o predi√ß√µes bin√°rias!
        metrics = {
            'auc_roc': roc_auc_score(y_true, y_probs_cal),  # CORRIGIDO: usa probabilidades
            'recall': recall_score(y_true, y_pred, zero_division=0),
            'f2_score': fbeta_score(y_true, y_pred, beta=2, zero_division=0),
            'f1_score': fbeta_score(y_true, y_pred, beta=1, zero_division=0),
            'auc_pr': average_precision_score(y_true, y_probs_cal),
            'optimal_threshold': best_threshold,
            'max_f2_score': best_f2
        };
        
        # M√©tricas adicionais de diagn√≥stico
        if len(np.unique(y_pred)) > 1:
            from sklearn.metrics import confusion_matrix
            
            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
            metrics.update({
                'precision': precision_score(y_true, y_pred, zero_division=0),
                'true_negatives': int(tn),
                'false_positives': int(fp),
                'false_negatives': int(fn),
                'true_positives': int(tp),
                'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0.0
            })
        
        # Adiciona thresholds candidatos para an√°lise
        for name, thresh in thresholds_candidates.items():
            metrics[f'threshold_{name}'] = thresh
        
        # üìù SEED CIENT√çFICO: ID determin√≠stico para verifica√ß√£o de reutiliza√ß√£o
        # Combina√ß√£o de nome do modelo, seed cient√≠fico e hashes determin√≠sticos
        unique_id = f"{model.__class__.__name__}_{inference_seed}_{prob_hash}_{pred_hash}"
        
        # Verifica√ß√£o de reutiliza√ß√£o de resultados (silencioso)
        if unique_id in globals().get('_results_cache', set()):
            pass  # Silencioso para logs limpos
        else:
            globals().setdefault('_results_cache', set()).add(unique_id)
            
        logging.debug(f"‚úÖ M√©tricas √∫nicas geradas para {model.__class__.__name__}: F2={metrics['f2_score']:.6f}, Recall={metrics['recall']:.6f}")
        
    return metrics


def setup_logging(log_file: str) -> None:
    """
    Configura o sistema de logging para arquivo e console.
    
    Args:
        log_file (str): Caminho para o arquivo de log
    """
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )


def monitor_concept_drift(model: nn.Module, data: HeteroData, test_metrics: Dict[str, float]) -> Dict[str, Any]:
    """
    Monitora concept drift usando 50 janelas deslizantes na m√°scara de monitoramento.
    
    Args:
        model: Modelo treinado
        data: Dados do grafo heterog√™neo com monitoring_mask
        test_metrics: M√©tricas de teste como baseline
    
    Returns:
        Dict com resultados do monitoramento de drift
    """
    logging.info("üîç INICIANDO MONITORAMENTO DE CONCEPT DRIFT")
    logging.info("="*80)
    
    # Verifica se existe monitoring_mask
    if not hasattr(data['transaction'], 'monitoring_mask'):
        logging.warning("‚ö†Ô∏è monitoring_mask n√£o encontrada. Pulando monitoramento de drift.")
        return {}
    
    monitoring_mask = data['transaction'].monitoring_mask
    monitoring_indices = torch.where(monitoring_mask)[0]
    
    if len(monitoring_indices) == 0:
        logging.warning("‚ö†Ô∏è Nenhuma amostra na monitoring_mask. Pulando monitoramento de drift.")
        return {}
    
    logging.info(f"üìä Amostras de monitoramento: {len(monitoring_indices):,}")
    logging.info(f"üìà Baseline (Teste): Recall={test_metrics.get('recall', 0):.4f}, F1={test_metrics.get('f1_score', 0):.4f}, F2={test_metrics.get('f2_score', 0):.4f}, AUC-PR={test_metrics.get('auc_pr', 0):.4f}, AUC-ROC={test_metrics.get('auc_roc', 0):.4f}")
    logging.info("")
    
    # Configura√ß√£o das janelas
    num_windows = 50
    total_samples = len(monitoring_indices)
    window_size = max(total_samples // num_windows, 20)  # M√≠nimo 20 amostras por janela
    
    # Ajusta n√∫mero de janelas se necess√°rio
    if window_size * num_windows > total_samples:
        num_windows = max(total_samples // window_size, 1)
    
    logging.info(f"üîß Configura√ß√£o: {num_windows} janelas, {window_size} amostras/janela")
    
    # Resultados das janelas
    window_results = []
    baseline_recall = test_metrics.get('recall', 0)
    baseline_f1 = test_metrics.get('f1_score', 0)
    baseline_f2 = test_metrics.get('f2_score', 0)
    baseline_auc_pr = test_metrics.get('auc_pr', 0)
    baseline_auc_roc = test_metrics.get('auc_roc', 0)
    
    model.eval()
    with torch.no_grad():
        # Forward pass completo
        logits = model(data)
        probs = torch.sigmoid(logits.squeeze())
        
        # Header do log
        logging.info("Janela | Amostras    | Recall  | F1      | F2      | AUC-PR  | AUC-ROC")
        logging.info("-" * 65)
        
        for window_idx in range(num_windows):
            start_idx = window_idx * window_size
            end_idx = min(start_idx + window_size, total_samples)
            
            if start_idx >= end_idx:
                break
                
            # √çndices da janela
            window_indices = monitoring_indices[start_idx:end_idx]
            
            # Dados da janela
            window_probs = probs[window_indices].cpu().numpy()
            window_labels = data['transaction'].y[window_indices].cpu().numpy()
            
            # Calcula m√©tricas da janela
            if len(np.unique(window_labels)) > 1:
                try:
                    from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, recall_score, fbeta_score
                    
                    auc_roc = roc_auc_score(window_labels, window_probs)
                    auc_pr = average_precision_score(window_labels, window_probs)
                    
                    # Otimiza threshold para F2
                    precision, recall, thresholds = precision_recall_curve(window_labels, window_probs)
                    f2_scores = (5 * precision * recall) / (4 * precision + recall + 1e-10)
                    best_f2_idx = np.argmax(f2_scores)
                    optimal_threshold = thresholds[best_f2_idx] if best_f2_idx < len(thresholds) else 0.5
                    
                    window_preds = (window_probs > optimal_threshold).astype(int)
                    
                    if len(np.unique(window_preds)) > 1:
                        recall_val = recall_score(window_labels, window_preds, zero_division=0)
                        f1_val = fbeta_score(window_labels, window_preds, beta=1, zero_division=0)
                        f2_val = fbeta_score(window_labels, window_preds, beta=2, zero_division=0)
                    else:
                        recall_val = f1_val = f2_val = 0.0
                    
                except Exception as e:
                    logging.warning(f"Erro na janela {window_idx+1}: {str(e)}")
                    recall_val = f1_val = f2_val = auc_pr = auc_roc = 0.0
            else:
                recall_val = f1_val = f2_val = auc_pr = auc_roc = 0.0
            
            # Calcula drift
            drift_recall = recall_val - baseline_recall
            drift_f1 = f1_val - baseline_f1
            drift_f2 = f2_val - baseline_f2
            drift_auc_pr = auc_pr - baseline_auc_pr
            drift_auc_roc = auc_roc - baseline_auc_roc
            
            # Log da janela
            sample_range = f"{start_idx+1}-{end_idx}"
            logging.info(f"{window_idx+1:6d} | {sample_range:11s} | {recall_val:.4f} | {f1_val:.4f} | {f2_val:.4f} | {auc_pr:.4f} | {auc_roc:.4f}")
            
            # Armazena resultado (converte para tipos JSON serializ√°veis)
            window_results.append({
                'window': int(window_idx + 1),
                'start_sample': int(start_idx + 1),
                'end_sample': int(end_idx),
                'num_samples': int(end_idx - start_idx),
                'recall': float(recall_val),
                'f1_score': float(f1_val),
                'f2_score': float(f2_val),
                'auc_pr': float(auc_pr),
                'auc_roc': float(auc_roc),
                'drift_recall': float(drift_recall),
                'drift_f1': float(drift_f1),
                'drift_f2': float(drift_f2),
                'drift_auc_pr': float(drift_auc_pr),
                'drift_auc_roc': float(drift_auc_roc)
            })
    
    if window_results:
        # Estat√≠sticas de drift
        all_drifts_recall = [w['drift_recall'] for w in window_results]
        all_drifts_f1 = [w['drift_f1'] for w in window_results]
        all_drifts_f2 = [w['drift_f2'] for w in window_results]
        all_drifts_auc_pr = [w['drift_auc_pr'] for w in window_results]
        all_drifts_auc_roc = [w['drift_auc_roc'] for w in window_results]
    
    # Resultados finais (converte para tipos JSON serializ√°veis)
    drift_results = {
        'baseline_metrics': {k: float(v) if isinstance(v, (np.floating, np.integer)) else v for k, v in test_metrics.items()},
        'monitoring_summary': {
            'total_samples': int(total_samples),
            'num_windows': int(len(window_results)),
            'window_size': int(window_size)
        },
        'window_results': window_results,
        'drift_analysis': {
            'mean_drift_recall': float(np.mean(all_drifts_recall)) if window_results else 0.0,
            'mean_drift_f1': float(np.mean(all_drifts_f1)) if window_results else 0.0,
            'mean_drift_f2': float(np.mean(all_drifts_f2)) if window_results else 0.0,
            'mean_drift_auc_pr': float(np.mean(all_drifts_auc_pr)) if window_results else 0.0,
            'mean_drift_auc_roc': float(np.mean(all_drifts_auc_roc)) if window_results else 0.0,
            'min_drift_recall': float(np.min(all_drifts_recall)) if window_results else 0.0,
            'min_drift_f1': float(np.min(all_drifts_f1)) if window_results else 0.0,
            'min_drift_f2': float(np.min(all_drifts_f2)) if window_results else 0.0,
            'min_drift_auc_pr': float(np.min(all_drifts_auc_pr)) if window_results else 0.0,
            'min_drift_auc_roc': float(np.min(all_drifts_auc_roc)) if window_results else 0.0
        }
    }
    
    return drift_results


def parse_arguments():
    """
    Parse command line arguments for R-GCN training specification.
    
    Returns:
        argparse.Namespace: Parsed arguments containing graph_type and other parameters
    """
    parser = argparse.ArgumentParser(
        description="Treinamento de modelo R-GCN para o Knowledge Graph IEEE-CIS",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplo de uso - IEEE-CIS R-GCN Knowledge Graph:
  # Treinar R-GCN:
  python 2_run_gnn_experiments_rgcn.py --graph-type knowledge_hetero
  
  # Treinar com configura√ß√µes espec√≠ficas:
  python 2_run_gnn_experiments_rgcn.py --epochs 200 --patience 30

Tipo de grafo heterog√™neo:
  - knowledge_hetero: Knowledge Graph multi-relacional com 6 tipos de n√≥s e 7 tipos de arestas
    * N√≥s: transaction, merchant, card, product_category, device, user
    * Arestas: transaction_merchant, transaction_card, transaction_product, 
              transaction_device, transaction_user, merchant_product, card_user
    * Features: Distribu√≠das entre diferentes tipos de n√≥s
    * Label: 'isFraud' apenas em n√≥s 'transaction' (0=leg√≠tima, 1=fraude)

Modelo:
  - R-GCN: Relational Graph Convolutional Network (multi-relacional)
  
Arquivo processado automaticamente:
  Knowledge Graph Heterog√™neo:
  - knowledge_hetero_data.pt (HeteroData com m√∫ltiplos tipos de n√≥s/arestas)
    * Estrutura heterog√™nea: Multi-relacional, multi-entidade
    * M√°scaras: train_mask, val_mask, test_mask apenas em n√≥s 'transaction'
    * Suporte completo a grafos heterog√™neos com PyTorch Geometric
        """
    )
    
    parser.add_argument(
        '--graph-type',
        choices=['knowledge_hetero'],
        default='knowledge_hetero',
        help='Tipo de grafo a ser processado (padr√£o: knowledge_hetero - Knowledge Graph heterog√™neo IEEE-CIS)'
    )
    
    parser.add_argument(
        '--epochs',
        type=int,
        default=400,
        help='N√∫mero de √©pocas de treinamento (padr√£o: 200)'
    )
    
    parser.add_argument(
        '--patience',
        type=int,
        default=40,
        help='Paci√™ncia para early stopping (padr√£o: 40)'
    )
    
    parser.add_argument(
        '--learning-rate',
        type=float,
        default=0.002,
        help='Taxa de aprendizado (padr√£o: 0.002)'
    )
    
    parser.add_argument(
        '--hidden-channels',
        type=int,
        default=128,
        help='N√∫mero de canais ocultos para R-GCN (padr√£o: 128)'
    )
    
    parser.add_argument(
        '--dropout',
        type=float,
        default=0.4,
        help='Taxa de dropout (padr√£o: 0.4)'
    )
    
    parser.add_argument(
        '--mixed-precision',
        action='store_true',
        default=True,
        help='Habilitar mixed precision training (padr√£o: True)'
    )
    
    parser.add_argument(
        '--save-checkpoints',
        action='store_true',
        default=True,
        help='Salvar checkpoints intermedi√°rios (padr√£o: True)'
    )
    
    return parser.parse_args()


def main():
    """
    Fun√ß√£o principal para treinamento e avalia√ß√£o do modelo R-GCN.
    """
    # Parse command line arguments
    args = parse_arguments()
    graph_type = args.graph_type
    num_epochs = args.epochs
    patience = args.patience
    learning_rate = args.learning_rate
    hidden_channels = args.hidden_channels
    dropout = args.dropout
    mixed_precision = args.mixed_precision
    save_checkpoints = args.save_checkpoints
    
    # Setup inicial
    # üî¨ SEED CIENT√çFICO: Usa deriva√ß√£o determin√≠stica da timestamp em vez do valor real
    # Isso garante reprodutibilidade completa em todas as execu√ß√µes
    seed_suffix = f"{SCIENTIFIC_SEED:06d}"
    log_file = f"logs/{graph_type}_rgcn_training_seed{seed_suffix}.log"
    
    # Cria diret√≥rio de logs se n√£o existir
    os.makedirs("logs", exist_ok=True)
    os.makedirs("temp", exist_ok=True)
    os.makedirs("results", exist_ok=True)
    
    setup_logging(log_file)
    
    logging.info("="*80)
    logging.info(f"INICIANDO TREINAMENTO DE MODELO R-GCN - {graph_type.upper()}")
    logging.info("METODOLOGIA MULTISTATGRAPH FRAMEWORK")
    logging.info("="*80)
    logging.info(f"üéØ Tipo de grafo: {graph_type}")
    logging.info(f"ü§ñ Modelo: R-GCN")
    logging.info(f"‚è±Ô∏è √âpocas: {num_epochs}")
    logging.info(f"‚è≥ Paci√™ncia: {patience}")
    logging.info(f"üìö Learning rate: {learning_rate}")
    logging.info(f"üî¨ MultiStatGraph: Grafos pr√©-normalizados sem normaliza√ß√£o adicional")
    
    # Configura√ß√£o do dispositivo
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logging.info(f"Dispositivo utilizado: {device}")
    
    if torch.cuda.is_available():
        logging.info(f"GPU detectada: {torch.cuda.get_device_name(0)}")
        logging.info(f"Mem√≥ria GPU dispon√≠vel: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # Hiperpar√¢metros otimizados para efici√™ncia de mem√≥ria e performance
    config = {
        # Otimizador (com valores dos argumentos)
        'learning_rate': learning_rate,
        'weight_decay': 1e-4,  # Aumentado para melhor regulariza√ß√£o
        'beta1': 0.9,
        'beta2': 0.999,
        'eps': 1e-8,
        
        # Treinamento (com valores dos argumentos)
        'num_epochs': num_epochs,
        'patience': patience,
        'adaptive_patience': True,  # Habilitado para permitir treinamento mais longo quando √∫til
        
        # Arquitetura (com valores dos argumentos)
        'hidden_channels': hidden_channels,
        'num_layers': 3,
        'dropout': dropout,
        
        # Loss function - üî¨ VALORES BALANCEADOS PARA REDUZIR FALSOS POSITIVOS
        'focal_alpha': 0.95,  # Reduzido de 0.99 para diminuir agressividade
        'focal_gamma': 2.5,   # Reduzido de 3.0 para melhor precision
        'pos_weight_multiplier': 25.0,  # Reduzido de 50.0 para balancear precision/recall
        
        # Schedulers
        'cosine_T0': 40,  # Aumentado para aquecimento mais longo
        'cosine_T_mult': 2,  # T_mult deve ser um inteiro >= 1
        'cosine_eta_min': 5e-7,  # Mais baixo para melhor converg√™ncia
        'plateau_factor': 0.7,  # Menos agressivo na redu√ß√£o
        'plateau_patience': 20,  # Mais paci√™ncia antes de reduzir LR
        
        # Regulariza√ß√£o
        'l2_initial': 5e-5,  # Reduzido para evitar over-regulariza√ß√£o
        'grad_clip_norm': 2.0,  # Aumentado para permitir gradientes maiores
        
        # Calibra√ß√£o e threshold
        'enable_calibration': True,
        'calibration_method': 'isotonic',
        'threshold_strategy': 'multi',
        
        # Mixed precision (com valor do argumento)
        'mixed_precision': mixed_precision,
        
        # Debugging
        'log_interval': 5,
        'save_checkpoints': save_checkpoints,
        
        # Otimiza√ß√µes de mem√≥ria
        'gradient_accumulation_steps': 2,  # Reduzido para atualizar pesos mais frequentemente
        'memory_efficient_mode': True,
        'clear_cache_frequency': 5  # Mais frequente para evitar OOM
    }
    
    logging.info("HIPERPAR√ÇMETROS OTIMIZADOS:")
    logging.info("-" * 40)
    for category in ['Otimizador', 'Treinamento', 'Arquitetura', 'Loss Function', 'Regulariza√ß√£o']:
        logging.info(f"{category}:")
        
        if category == 'Otimizador':
            params = ['learning_rate', 'weight_decay', 'beta1', 'beta2', 'eps']
        elif category == 'Treinamento':
            params = ['num_epochs', 'patience', 'adaptive_patience', 'mixed_precision']
        elif category == 'Arquitetura':
            params = ['hidden_channels', 'num_layers', 'dropout', 'num_heads']
        elif category == 'Loss Function':
            params = ['focal_alpha', 'focal_gamma', 'pos_weight_multiplier']
        elif category == 'Regulariza√ß√£o':
            params = ['l2_initial', 'grad_clip_norm', 'enable_calibration']
        
        for param in params:
            if param in config:
                logging.info(f"  {param}: {config[param]}")
    
    # Carrega o grafo heterog√™neo
    base_dir = "data/graph/ieee-cis"
    global_graph_path = os.path.join(base_dir, "knowledge_hetero_data.pt")
    
    logging.info("üîÑ MODO GRAFO HETEROG√äNEO MULTI-RELACIONAL:")
    logging.info(f"  Arquivo: {global_graph_path}")
    logging.info("  üèóÔ∏è Estrutura heterog√™nea: 6 tipos de n√≥s + 7 tipos de arestas para m√°xima performance")
    logging.info("  üé≠ M√°scaras integradas: train_mask, val_mask, test_mask nos n√≥s de transa√ß√£o")
    
    # Configura√ß√£o do modelo R-GCN para grafos de conhecimento
    model_config = {
        'name': 'R-GCN',
        'class': RGCNModel,
        'params': {
            'hidden_channels': config['hidden_channels'],
            'dropout': config['dropout'],
            'num_layers': config['num_layers'],
        }
    }
    
    logging.info("Carregando conjuntos de dados...")
    
    # Carregamento dos dados
    try:
        # üöÄ MODO GRAFO HETEROG√äNEO: Carrega um √∫nico grafo heterog√™neo com m√°scaras
        logging.info("üîÑ Carregando grafo HETEROG√äNEO com m√°scaras integradas...")
        hetero_data = load_hetero_graph(global_graph_path, device, graph_type)
        
        # üî¨ VALIDA√á√ÉO CIENT√çFICA: Verificar integridade dos dados reais
        if not validate_real_graph_data(hetero_data):
            raise ValueError("‚ùå ERRO CIENT√çFICO: Dados do grafo n√£o s√£o v√°lidos para experimentos cient√≠ficos")
        
        logging.info("üî¨ Dados validados - Experimento cient√≠fico pode prosseguir")
        
        # O mesmo objeto √© usado para todos os splits, diferenciado pelas m√°scaras
        train_data = hetero_data
        val_data = hetero_data  
        test_data = hetero_data
        
        logging.info("‚úÖ Grafo heterog√™neo carregado com sucesso!")
        logging.info(f"üìä Total de n√≥s de transa√ß√£o: {hetero_data['transaction'].num_nodes:,}")
        
        # Conta total de arestas
        total_edges = 0
        for edge_type in hetero_data.edge_types:
            total_edges += hetero_data[edge_type].edge_index.size(1)
        logging.info(f"üîó Total de arestas heterog√™neas: {total_edges:,}")
        
        # Configura in_channels baseado nas features dos n√≥s de transa√ß√£o
        transaction_features = hetero_data['transaction'].x.shape[1]
        
        logging.info(f"üîß Configurando modelos heterog√™neos para {transaction_features} features de transa√ß√£o")
        logging.info(f"üéØ Knowledge Graph: 6 tipos de n√≥s, 7 tipos de arestas para aprendizado multi-relacional")
        
        # Log da configura√ß√£o estrutural
        logging.info(f"üèóÔ∏è ESTRUTURA HETEROG√äNEA: 6 camadas de conectividade multi-relacional para aprendizado estrutural avan√ßado")
        logging.info(f"üé≠ M√°scaras dispon√≠veis: train_mask, val_mask, test_mask")
            
        logging.info(f"üî¨ METODOLOGIA: Adapta√ß√£o din√¢mica por tipo de grafo conclu√≠da")
        logging.info(f"üìä Features por n√≥ de transa√ß√£o: {hetero_data['transaction'].x.shape[1]}")
        logging.info(f"üîó Estrutura heterog√™nea: {len(hetero_data.node_types)} tipos de n√≥s, {len(hetero_data.edge_types)} tipos de arestas")
            
        # Log da distribui√ß√£o de classes usando as m√°scaras para mostrar distribui√ß√£o por split
        for split_name, mask_attr in [('Train', 'train_mask'), ('Val', 'val_mask'), ('Test', 'test_mask')]:
            if hasattr(hetero_data['transaction'], mask_attr):
                mask = getattr(hetero_data['transaction'], mask_attr)
                split_labels = hetero_data['transaction'].y[mask]
                class_counts = torch.bincount(split_labels)
                if len(class_counts) >= 2:
                    fraud_rate = 100 * class_counts[1] / mask.sum()
                    logging.info(f"{split_name} - Distribui√ß√£o de classes: Normal={class_counts[0]}, "
                               f"Fraude={class_counts[1]} (Taxa: {fraud_rate:.2f}%)")
        
        # Calcula pesos das classes baseado apenas no conjunto de treino mascarado
        if hasattr(hetero_data['transaction'], 'train_mask'):
            train_labels_masked = hetero_data['transaction'].y[hetero_data['transaction'].train_mask]
            train_class_counts = torch.bincount(train_labels_masked)
        else:
            train_class_counts = torch.bincount(hetero_data['transaction'].y)
            logging.warning("‚ö†Ô∏è train_mask n√£o encontrada, usando todos os n√≥s para calcular pesos")
        
        total_samples = train_class_counts.sum().float()
        class_weights = total_samples / (2.0 * train_class_counts.float())
        logging.info(f"Pesos das classes calculados: Normal={class_weights[0]:.4f}, Fraude={class_weights[1]:.4f}")
            
    except Exception as e:
        logging.error(f"Erro ao carregar dados: {str(e)}")
        return
    
    # Verifica√ß√£o de mem√≥ria
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        gpu_allocated = torch.cuda.memory_allocated(0) / 1e9
        gpu_reserved = torch.cuda.memory_reserved(0) / 1e9
        logging.info(f"GPU: {gpu_memory:.1f}GB total, {gpu_allocated:.1f}GB alocada, {gpu_reserved:.1f}GB reservada")
    
    logging.info("CONFIGURA√á√ÉO DO MODELO:")
    logging.info(f"{model_config['name']}:")
    for param, value in model_config['params'].items():
        logging.info(f"  {param}: {value}")
    logging.info("")
    
    # Dicion√°rio para armazenar resultados
    all_results = {}
    trained_model = None  # Vari√°vel para manter refer√™ncia do modelo treinado
    
    # Treinamento do modelo R-GCN
    model_name = model_config['name']
    model_class = model_config['class']
    model_params = model_config['params']
    
    # üî¨ SEED CIENT√çFICO: Mesmo seed para todos os experimentos
    model_seed = SCIENTIFIC_SEED  # Usa o seed global definido no in√≠cio do script
    
    # üî¨ RIGOR CIENT√çFICO: Aplica seeds em todas as camadas para garantir reprodutibilidade
    np.random.seed(model_seed)
    torch.manual_seed(model_seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(model_seed)
        torch.cuda.manual_seed_all(model_seed)
    
    # üî¨ SEED CONSISTENTE: Para bibliotecas Python que usam random
    import random
    random.seed(model_seed)
    
    # üî¨ TORCH BACKEND: For√ßa determinismo completo
    torch.backends.cudnn.deterministic = True  # Garante resultados id√™nticos
    torch.backends.cudnn.benchmark = False     # Desativa otimiza√ß√µes n√£o-determin√≠sticas
    
    logging.info("="*60)
    logging.info(f"INICIANDO TREINAMENTO PARA {model_name} NO {graph_type.upper()}GRAPH")
    logging.info(f"üî¨ Seed cient√≠fico: {model_seed} (id√™ntico para todos os experimentos)")
    logging.info(f"üîß Seeds aplicados: numpy, torch, random, cuda")
    logging.info("="*60)
    
    # Inicializa modelo, otimizador e crit√©rio
    # Para modelos heterog√™neos, passa o HeteroData como primeiro argumento
    model = model_class(hetero_data, **model_params).to(device)
    
    # üî¨ INICIALIZA√á√ÉO CIENT√çFICA PADR√ÉO: Aplica inicializa√ß√µes recomendadas pela literatura
    ensure_model_reproducibility(model, model_name, model_seed)
    
    # Otimizador AdamW com learning rate id√™ntico para todos os experimentos
    # Mant√©m configura√ß√£o cient√≠fica padr√£o para garantir compara√ß√£o justa
    model_lr = config['learning_rate']  # Mesmo learning rate para todos os experimentos
    
    logging.info(f"üìö Learning rate padr√£o para {graph_type}: {model_lr:.6f}")
    
    # Configura√ß√£o consistente de otimizador
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=model_lr,
        weight_decay=config['weight_decay'],
        betas=(config['beta1'], config['beta2']),
        eps=config['eps']
    )
    
    logging.info(f"üìö Learning rate para {model_name}: {model_lr:.6f}")
    
    # Scheduler com warmup e cosine annealing otimizado
    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
    scheduler_cosine = CosineAnnealingWarmRestarts(
        optimizer, 
        T_0=config['cosine_T0'], 
        T_mult=config['cosine_T_mult'], 
        eta_min=config['cosine_eta_min']
    )
    
    # Scheduler adicional para plateau com configura√ß√µes otimizadas
    scheduler_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='max', 
        factor=config['plateau_factor'], 
        patience=config['plateau_patience'], 
        min_lr=config['cosine_eta_min']
    )
    
    # Mixed precision training se habilitado e dispon√≠vel
    scaler = None
    if config['mixed_precision'] and device.type == 'cuda':
        scaler = torch.amp.GradScaler()
        logging.info("Mixed precision training habilitado")
    
    criterion = nn.BCEWithLogitsLoss()
    
    # Informa√ß√µes detalhadas do modelo
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    logging.info(f"Modelo {model_name} inicializado:")
    logging.info(f"  Total de par√¢metros: {total_params:,}")
    logging.info(f"  Par√¢metros trein√°veis: {trainable_params:,}")
    logging.info(f"  Tamanho do modelo: ~{total_params * 4 / 1024 / 1024:.2f} MB")
    
    # Vari√°veis para early stopping e tracking melhorado
    best_val_f1 = 0.0  # Mudado para F1-Score como m√©trica principal equilibrada
    best_val_auc = 0.0
    best_model_state = None
    patience_counter = 0
    
    # Listas para tracking das m√©tricas
    train_losses = []
    train_f1_scores = []  # Mudado para F1
    val_aucs = []
    val_f1_scores = []    # Mudado para F1
    learning_rates = []
    
    logging.info(f"Iniciando treinamento por {config['num_epochs']} √©pocas...")
    
    for epoch in range(config['num_epochs']):
        # Treinamento com m√©tricas avan√ßadas
        current_train_data = hetero_data
        
        # Define m√°scara de treinamento
        train_mask = current_train_data['transaction'].train_mask if hasattr(current_train_data['transaction'], 'train_mask') else None
            
        train_loss, train_metrics = train_one_epoch(
            model, current_train_data, optimizer, criterion, None, 
            epoch, config['num_epochs'], scaler, model_name, graph_type, train_mask
        )
        
        train_losses.append(train_loss)
        train_f1_scores.append(train_metrics['train_recall'])  # Usar recall como proxy
        learning_rates.append(optimizer.param_groups[0]['lr'])
        
        # Avalia√ß√£o no conjunto de valida√ß√£o com calibra√ß√£o
        current_val_data = hetero_data
        
        # Define m√°scara de valida√ß√£o
        val_mask = current_val_data['transaction'].val_mask if hasattr(current_val_data['transaction'], 'val_mask') else None
            
        val_metrics = evaluate_model(model, current_val_data, calibrate_probs=True, 
                                   graph_type=graph_type, split_mask=val_mask)
        val_auc = val_metrics['auc_roc']
        val_f1 = val_metrics['f1_score']  # Mudado para F1
        
        val_aucs.append(val_auc)
        val_f1_scores.append(val_f1)  # Mudado para F1
        
        # Ajusta learning rate com ambos schedulers
        scheduler_cosine.step()
        scheduler_plateau.step(val_f1)  # Usa F1-Score para plateau
        
        # Early stopping baseado em F1-Score (m√©trica equilibrada)
        improved = False
        if val_f1 > best_val_f1:
            best_val_f1 = val_f1
            best_val_auc = val_auc
            best_model_state = model.state_dict().copy()
            patience_counter = 0
            improved = True
        else:
            patience_counter += 1
        
        # Early stopping com paci√™ncia adaptativa baseada em configura√ß√£o
        if config['adaptive_patience']:
            # Paci√™ncia aumenta gradualmente: base + (epoch // 50) * 10, max 2x base
            adaptive_patience = min(
                config['patience'] + (epoch // 50) * 10, 
                config['patience'] * 2
            )
        else:
            adaptive_patience = config['patience']
            
        if patience_counter >= adaptive_patience:
            logging.info(f"Early stopping acionado na √©poca {epoch+1}. "
                       f"Paci√™ncia utilizada: {adaptive_patience}. "
                       f"Melhor Val F1: {best_val_f1:.4f}, Melhor Val AUC: {best_val_auc:.4f}")
            break
            
        # Log de debugging para casos de performance muito baixa
        if epoch > 100 and val_f1 < 0.05:
            logging.warning(f"Performance muito baixa detectada na √©poca {epoch+1}. "
                          f"Verificando configura√ß√µes...")
            logging.warning(f"  Val F1: {val_f1:.6f}, Threshold: {val_metrics['optimal_threshold']:.6f}")
            logging.warning(f"  True Positives: {val_metrics.get('true_positives', 0)}")
            logging.warning(f"  Learning Rate: {optimizer.param_groups[0]['lr']:.2e}")
            
        # Checkpoint intermedi√°rio a cada 50 √©pocas se habilitado
        if config['save_checkpoints'] and (epoch + 1) % 50 == 0:
            checkpoint_path = f"temp/{model_name.lower()}_{graph_type}_checkpoint_epoch_{epoch+1}.pt"
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_f1': val_f1,
                'val_auc': val_auc
            }, checkpoint_path)
            logging.info(f"Checkpoint salvo: {checkpoint_path}")
        
        # Limpeza de cache para otimiza√ß√£o de mem√≥ria
        if torch.cuda.is_available() and (epoch + 1) % config['clear_cache_frequency'] == 0:
            torch.cuda.empty_cache()
            if (epoch + 1) % 20 == 0:
                logging.info(f"Cache GPU limpo na √©poca {epoch+1}")
    
    # Carrega o melhor modelo
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        logging.info(f"Melhor modelo carregado (Val F1: {best_val_f1:.4f}, Val AUC: {best_val_auc:.4f})")
    
    # Mant√©m refer√™ncia do modelo para monitoramento de drift
    trained_model = model
    
    # Avalia√ß√£o final completa no conjunto de teste
    logging.info("Avaliando modelo no conjunto de teste com calibra√ß√£o...")
    current_test_data = hetero_data
    
    # üî¨ SEED CIENT√çFICO PARA AVALIA√á√ÉO - Usa mesmo seed para todos os experimentos
    eval_seed = SCIENTIFIC_SEED  # Usa o mesmo seed cient√≠fico para avalia√ß√£o
    np.random.seed(eval_seed)
    torch.manual_seed(eval_seed)
    logging.info(f"üî¨ Seed cient√≠fico para avalia√ß√£o: {eval_seed} (consistente para todos os experimentos)")
    
    # Define m√°scara de teste
    test_mask = current_test_data['transaction'].test_mask if hasattr(current_test_data['transaction'], 'test_mask') else None
        
    test_metrics = evaluate_model(model, current_test_data, calibrate_probs=True, 
                                graph_type=graph_type, split_mask=test_mask)
    
    # üîç VERIFICA√á√ÉO CIENT√çFICA: Sem detec√ß√£o de cache for√ßada
    # Mant√©m probabilidades naturais do modelo para valida√ß√£o cient√≠fica
    logging.info(f"‚úÖ Avalia√ß√£o cient√≠fica registrada para {model_name}")
    
    # Avalia√ß√£o adicional no conjunto de valida√ß√£o para compara√ß√£o
    current_val_data = hetero_data
    
    # Define m√°scara de valida√ß√£o para avalia√ß√£o final
    val_mask_final = current_val_data['transaction'].val_mask if hasattr(current_val_data['transaction'], 'val_mask') else None
        
    val_final_metrics = evaluate_model(model, current_val_data, calibrate_probs=True, 
                                         graph_type=graph_type, split_mask=val_mask_final)
    
    # Log das m√©tricas finais detalhadas
    logging.info("="*60)
    logging.info(f"M√âTRICAS FINAIS {model_name} - {graph_type.upper()}GRAPH - CONJUNTO DE TESTE:")
    logging.info("="*60)
    
    # M√©tricas principais
    main_metrics = ['auc_roc', 'auc_pr', 'f2_score', 'f1_score', 'recall', 'precision']
    for metric in main_metrics:
        if metric in test_metrics:
            logging.info(f"  {metric.upper().replace('_', '-')}: {test_metrics[metric]:.4f}")
    
    # M√©tricas de diagn√≥stico
    logging.info("  " + "-" * 40)
    logging.info("  DIAGN√ìSTICO DETALHADO:")
    
    diag_metrics = ['true_positives', 'false_positives', 'true_negatives', 'false_negatives',
                   'specificity']
    for metric in diag_metrics:
        if metric in test_metrics:
            value = test_metrics[metric]
            if isinstance(value, int):
                logging.info(f"    {metric.replace('_', ' ').title()}: {value}")
            else:
                logging.info(f"    {metric.replace('_', ' ').title()}: {value:.4f}")
    
    # Informa√ß√µes sobre threshold
    logging.info("  " + "-" * 40)
    logging.info("  THRESHOLD:")
    logging.info(f"    Optimal Threshold: {test_metrics['optimal_threshold']:.4f}")
    
    # Salva o modelo treinado
    model_save_path = f"temp/{model_name.lower()}_{graph_type}_best.pt"
    torch.save(best_model_state, model_save_path)
    logging.info(f"Modelo salvo em: {model_save_path}")
    
    # Armazena resultados
    all_results[model_name] = {
        'best_val_f1': best_val_f1,
        'best_val_auc': best_val_auc,
        'test_metrics': test_metrics,
        'val_final_metrics': val_final_metrics,
        'config': model_params,
        'training_epochs': epoch + 1,
        'model_save_path': model_save_path,
        'training_history': {
            'train_losses': train_losses,
            'val_aucs': val_aucs,
            'val_f1_scores': val_f1_scores,
            'learning_rates': learning_rates
        }
    }
    
    # üßπ LIMPEZA CR√çTICA: For√ßa reset completo
    del model, optimizer, scheduler_cosine, scheduler_plateau
    if 'scaler' in locals() and scaler is not None:
        del scaler
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        
    logging.info(f"‚úÖ Modelo {model_name} conclu√≠do")
    logging.info("-" * 60)
    
    # Relat√≥rio final
    logging.info("="*80)
    logging.info(f"RELAT√ìRIO FINAL COMPARATIVO - {graph_type.upper()}")
    logging.info("MULTISTATGRAPH FRAMEWORK - AN√ÅLISE COMPLETA DE PERFORMANCE")
    logging.info("="*80)
    
    # Tabela comparativa principal
    logging.info("TABELA COMPARATIVA PRINCIPAL:")
    logging.info(f"{'Modelo':<10} {'AUC-ROC':<10} {'AUC-PR':<10} {'F1-Score':<10} {'F2-Score':<10} {'Recall':<10} {'Precision':<10} {'Threshold':<10}")
    logging.info("-" * 80)
    
    for model_name, results in all_results.items():
        metrics = results['test_metrics']
        threshold = metrics.get('optimal_threshold', 0.5)
        precision = metrics.get('precision', 0.0)
        f1_score = metrics.get('f1_score', 0.0)
        logging.info(f"{model_name:<10} {metrics['auc_roc']:<10.4f} {metrics['auc_pr']:<10.4f} "
                    f"{f1_score:<10.4f} {metrics['f2_score']:<10.4f} {metrics['recall']:<10.4f} {precision:<10.4f} {threshold:<10.3f}")
    
    # An√°lise de confusion matrix
    logging.info("\nAN√ÅLISE DE CONFUSION MATRIX:")
    logging.info(f"{'Modelo':<10} {'TP':<8} {'FP':<8} {'TN':<8} {'FN':<8} {'Especificidade':<15} {'Sensibilidade':<15}")
    logging.info("-" * 80)
    
    for model_name, results in all_results.items():
        metrics = results['test_metrics']
        tp = metrics.get('true_positives', 0)
        fp = metrics.get('false_positives', 0)
        tn = metrics.get('true_negatives', 0)
        fn = metrics.get('false_negatives', 0)
        spec = metrics.get('specificity', 0)
        sens = metrics.get('sensitivity', 0)
        
        logging.info(f"{model_name:<10} {tp:<8} {fp:<8} {tn:<8} {fn:<8} {spec:<15.4f} {sens:<15.4f}")
    
    # Salva resultados em JSON
    # üî¨ SEED CIENT√çFICO: Usa identificador determin√≠stico baseado na seed
    # Garante reprodutibilidade e rastreabilidade total de resultados
    results_file = f"results/{graph_type}_rgcn_performance_seed{seed_suffix}.json"
    
    # Adiciona metadados aos resultados
    final_results = {
        'metadata': {
            'seed': SCIENTIFIC_SEED,
            'graph_type': graph_type,
            'model': 'R-GCN',
            'dataset': 'IEEE-CIS',
            'epochs': num_epochs,
            'patience': patience,
            'learning_rate': learning_rate,
            'device': str(device),
            'mixed_precision': mixed_precision
        },
        'hyperparameters': config,
        'results': {}
    }
    
    # Converte resultados para formato serializ√°vel
    for model_name, results in all_results.items():
        # Filtra apenas valores num√©ricos das m√©tricas de teste
        numeric_test_metrics = {}
        for k, v in results['test_metrics'].items():
            if k != 'unique_model_id':  # Exclui IDs que s√£o strings
                try:
                    numeric_test_metrics[k] = float(v)
                except (ValueError, TypeError):
                    logging.warning(f"‚ö†Ô∏è M√©trica n√£o num√©rica ignorada: {k}={v}")
        
        final_results['results'][model_name] = {
            'test_metrics': numeric_test_metrics,
            'training_epochs': int(results['training_epochs']),
            'best_val_f1': float(results['best_val_f1']),
            'best_val_auc': float(results['best_val_auc'])
        }
    with open(results_file, 'w') as f:
        json.dump(final_results, f, indent=2)
    
    logging.info(f"\nResultados salvos em: {results_file}")
    
    # Monitoramento de Concept Drift
    if all_results and hasattr(hetero_data['transaction'], 'monitoring_mask'):
        logging.info("\n" + "="*80)
        
        # Pega o primeiro (e √∫nico) modelo treinado
        model_name, model_results = list(all_results.items())[0]
        test_metrics = model_results['test_metrics']
        
        # Executa monitoramento de drift
        drift_results = monitor_concept_drift(trained_model, hetero_data, test_metrics)
        
        # Salva resultados de drift
        if drift_results:
            drift_file = f"results/{graph_type}_rgcn_drift_analysis_seed{seed_suffix}.json"
            with open(drift_file, 'w') as f:
                json.dump(drift_results, f, indent=2)
            logging.info(f"üìä Resultados do drift salvos em: {drift_file}")
    
    # Resultado final
    if all_results:
        model_result = list(all_results.items())[0]
        logging.info(f"\nüèÜ MODELO R-GCN: {model_result[0]} (F1-Score: {model_result[1]['test_metrics']['f1_score']:.4f})")
    
    logging.info("="*80)
    logging.info(f"‚úÖ TREINAMENTO R-GCN {graph_type.upper()} CONCLU√çDO COM SUCESSO!")
    logging.info("üî¨ MULTISTATGRAPH FRAMEWORK - EXPERIMENTO FINALIZADO")
    logging.info("="*80)


if __name__ == "__main__":
    main()
